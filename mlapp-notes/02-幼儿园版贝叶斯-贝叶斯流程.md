# 一次完整的贝叶斯统计操作流程

## 用伯努利抛硬币

和上一篇一样，我们用简单的伯努利分布(两点分布)举例子。
$$
p(x|\theta)=\theta^x(1-\theta)^{(1-x)}
$$
关于这种表示方式，以及条件概率相关的解释，请看上一篇：

参数的分布可以很容易地表示出来：
$$
p(\theta|x)=\frac{p(x|\theta)}{p(x)}p(\theta)
$$
只要简单地**加减乘除**一顿操作，就可以求出参数$\theta$的分布。这样简单的操作显然不可行，因为$p(x|\theta)$是等式右边唯一已知量，其余两个都是抽象的。

## 各种术语

了解术语有助于听懂别人吹牛，不了解术语相当于没学过。在讲术语的过程中，可以同时理解贝叶斯统计的相应流程。

### 似然(Likelihood)

$p(x|\theta)$被称为似然，在这里，它是等式右边唯一有表达式的，在我们的例子里：
$$
p(x|\theta)=\theta^x(1-\theta)^{(1-x)}
$$
再写一遍表达式只是想让你放心一些，重点不在表达式本身。你可能在学习考研数学的时候计算过「最大似然估计」，你现在将会理解这个计算过程。

#### 从概率理解

一个明显的事实是，「似然」是随机变量的概率密度分布，是$x$的函数。**似然是数据出现的概率**，我们统计采样调查得到的数据，它们出现的概率就是似然。更严谨地说，**似然是在给定参数前提下，数据出现的概率**，这样说就把条件概率的记号给体现出来了。

似然是出现在分子的位置上的，如果一些参数的取值可以让似然的取值更大，也就是在参数去这些值的时候相同数据样本出现的概率更大，那么就更有可能去这些值。也可以反过来说，如果参数取了一些值，使得收集到的数据样本的出现概率不大，这明显和「数据确实被收集到了」这一事实矛盾，故参数取这些值的概率不大。

#### 从记号理解

在统计学语境下，我们关心的是参数$\theta$的变化，似然固然也是$\theta$的函数。由次可以从另一种方面理解，对于在｜左边的变量，这是概率密度函数，对于在｜右边的变量，就是「似然」。同样套到更广泛的记号上去，$p(A|B)$是A的概率密度函数，是B的似然函数。

你可以想一想为什么要这样称呼，这不是特别重要。可以这样理解这个称呼：

> 有了这些数据，

似然不是概率密度函数，全空间积分不是1。在伯努利模型下，可以试一下计算“似然”的积分：
$$
\int_0^1\theta^x(1-\theta)^{(1-x)}d\theta=\int_0^1\theta d\theta=\frac{1}{2}
$$
不要被指数上的$x$吓到了，$x$的取值是离散的$0,1$。

在这里，我们关心$\theta$而不是已经有已知数据的$x$，$p(x|\theta)$叫做似然而不叫概率密度也就理所当然。

### 先验(Prior)

叫做「先验」的是$p(\theta)$，好像是不知道哪里来的一项。它没办法从统计数据中获得，也没办法从已有的概率分布中获得。它的确是一个「凭空冒出来」的函数。

**先验**是对目标估计量的预先印象。(这句话好像没说什么…) 要知道抛硬币后某一面朝上的概率是多少，你一定会猜一个$0.5$，或者你至少认为这个概率和$0.5$相去不远。这就是一种「先验」。我们固然要估计参数的分布，但这不妨我们先猜一个分布，并且给让$p(\theta)$反应这种「猜」。

一些了解机器学习的朋友可能知道线性回归的正则项：
$$
L(\vec\omega)=(y-\widehat y)^2+\lambda||\vec\omega||_2^2
$$
正则项就是对要估计的参数$\vec\omega$的一种假设，假设各个系数和0相去不远。这种假设反应在最终的计算中，让模型免疫一些特别离群的数据。

在抛硬币的例子里，我们猜$\theta=0.5$，可以采用很多不同的形式，只要满足距0.5相去不远即可。可以是一个方差很小的正态分布:
$$
\theta\sim N(0.5,0.0000001)
$$
这样的假设当然会反应在最终概率分布的计算结果中。

### 后验(Posterior)

后验就是我们要计算的最终目标$p(\theta|x)$。无须多言。

### 分母

最后没有说的是在分母上的$p(x)$。它的名字当然不只是「分母」，这里特意不给出，以弱化它的作用。事实上，分母的作用仅限于**让后验是个分布**。似然和先验的乘积很可能(对参数$\theta$)积分不为1，而后验又必须是个概率密度函数，必须积分到1，故分母充当归一化系数。

分母和参数无关，关注参数变化，将原本随机变量取值视作已知，常常可以在计算中忽略分母。它不会影响导数(梯度)的符号，不会影响极大值的确定。我们甚至不把它写进贝叶斯公式：
$$
p(\theta|x)\propto p(x|\theta)p(\theta)
$$
或者写得更直观一点：
$$
posterior=likelihood\times prior
$$
我们暂且对分母的其他功能按下不表。

## 继续拿伯努利抛硬币

回到估计抛硬币概率的例子。

### 似然

这可能是你第一次正确计算似然，所以一定要专心哦。

我在写这一段的时候，想直接以「带公式」掠过，后来发觉详细描述一遍对自己加深理解很有好处，故详细描述一下。

要记得，**似然是数据出现的概率**。抛硬币的数据是一系列类似于 0 1 0 0 1 1 0 1 之类的表示正反两面的记录。单独一次抛硬币的概率由概率密度函数描述：
$$
p(x_i|\theta)=\theta^{x_i}(1-\theta)^{(1-x_i)},i=0,1,2...,x_i\in\{0,1\}
$$
连续抛好几次硬币的概率呢？你可能会写出这样的