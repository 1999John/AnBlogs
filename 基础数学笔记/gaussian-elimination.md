#! https://zhuanlan.zhihu.com/p/268637430
# 深入理解高斯消元法：解方程、线性相关和有解的条件｜线性代数笔记

本文透彻讲解高斯消元法的各种意义和过程，不局限于它的解方程功能，探索更深刻的含义。先讲解解方程的过程，再介绍相关的概念、解读背后的原理。如果你已经熟悉使用高斯消元法解方程组，可选择性跳过部分内容。

本文的md源码文件：[AnBlogs](https://github.com/Anarion-zuo/AnBlogs/tree/master/基础数学笔记/gaussian-elimination.md)

[TOC]

## 可逆矩阵的简单情况

你一定会解简单的线性方程组，比如下面这样的：
$$
\text{Equ}_1:\begin{align}
&2x_1+4x_2-2x_3=2\\
&4x_1+9x_2-3x_3=8\\
&-2x_1-3x_2+7x_3=10
\end{align}
$$
你一定知道，消元的过程就是解方程的过程。对于上面的方程组，$(1)+(3)$、$(1)\times 2-(2)$可以消掉$x_1$，得到的两个方程进一步可以消掉$x_2$或$x_3$，进而解得结果。

这个过程可以用矩阵描述，表达的是相同含义。

把方程组左边变量前的系数放进矩阵：
$$
A=\begin{pmatrix}
2 & 4 & -2\\
4 & 9 & -3\\
-2 & -3 & 7\\
\end{pmatrix}
$$
把方程组右边数字放进矩阵：
$$
b=\begin{pmatrix}
2\\
8\\
10\\
\end{pmatrix}
$$
原方程可以写成：
$$
Ax=b
$$


接下来进行消元的过程。由于等式之间的加减法同时操作等式两边，以上两个矩阵$A,b$的「行变换」需要同时进行，故把它们放进同一个矩阵：
$$
A'=\begin{pmatrix}
2 & 4 & -2 & 2\\
4 & 9 & -3 & 8\\
-2 & -3 & 7 & 10\\
\end{pmatrix}
$$

先消掉$(2),(3)$中的$x_1$，也就是把矩阵第2，3行的第一列变为0。将第1行直接加到第3行、乘2后减去第2行，可以实现这个效果：
$$
A^{(1)}=\begin{pmatrix}
2 & 4 & -2 & 2\\
0 & 1 & 1 & 4\\
0 & 1 & 5 & 12\\
\end{pmatrix}
$$
相当于保持第一个方程不变，使用第一个方程，在第2，3中消去了$x_1$。新的第2，3方程如下：
$$
\text{Equ}_2:\begin{align}
&x_2+x_3=4\\
&x_2+5x_3=12
\end{align}
$$
上面的操作可以看出，把矩阵的一行乘上某个数字，再加/减到另一行，可以看作把方程组中的两个方程拿出来，让他们的等式两边相互加减，就是我们熟悉的消元手法！

上式可以再看成一个二元一次方程组，在其中的一个方程中消去$x_2$或$x_3$，就可以解出这个方程组，再通过带入$\text{Equ}_1$第一个方程解出$x_1$。

我们用矩阵的语言描述消去$x_2$的过程。在已经得到$A^{(1)}$的前提下，使用第2行，把$A^{(1)}$第3行第2列的数字变成0，也就是消去$x_2$的过程。得到的矩阵如下：
$$
A^{(2)}=\begin{pmatrix}
2 & 4 & -2 & 2\\
0 & 1 & 1 & 4\\
0 & 0 & 4 & 8\\
\end{pmatrix}
$$
第三行表达成方程：
$$
\text{Equ}_3:4x_3=8
$$
为了解出$x_3$，得到$x_3=…$的形式，要给$\text{Equ}_3$两边同时除以$4$，得到$\text{Equ}_4:x_3=2$。矩阵也对应操作，$A^{(2)}$第3行除以$4$：
$$
A^{(3)}=\begin{pmatrix}
2 & 4 & -2 & 2\\
0 & 1 & 1 & 4\\
0 & 0 & 1 & 2\\
\end{pmatrix}
$$
把$x_3$带入$\text{Equ}_2$的任意一个方程都可以解出$x_2$。因为上步操作中，把$\text{Equ}_2$的第二个方程的$x_2$消去了，所以现在把$\text{Equ}_4:x_3=2$带入第一个方程，相当于等式两边同时减去$\text{Equ}_4:x_3=2$，得到$\text{Equ}_5:x_2=2$。对应矩阵操作，是拿$A^{(3)}$的第3行去减第2行：
$$
A^{(4)}=\begin{pmatrix}
2 & 4 & -2 & 2\\
0 & 1 & 0 & 2\\
0 & 0 & 1 & 2\\
\end{pmatrix}
$$
把已经得到的$x_2,x_3$带入$\text{Equ}_1$的任意一个方程，都可以得到$x_1=1$，这里带入第一个，理由和刚才一样，2、3都已经用过了。对应矩阵操作，把$A^{(4)}$的第1行第2，3列变成0，把第1列变成1:
$$
A^{(5)}=\begin{pmatrix}
1 & 0 & 0 & 1\\
0 & 1 & 0 & 2\\
0 & 0 & 1 & 2\\
\end{pmatrix}
$$
方程的解是$(1,2,2)$，可以直接由最右列看出。

## 看看解方程的过程

以下说的「上三角」和「单位矩阵」均忽略最右侧的一列，因为最右侧是方程右边的常数。

解方程的过程可以分成两个阶段，不看最右列，前期得到一个上三角矩阵$A^{(3)}$，后期得到一个单位矩阵$A^{(5)}$。

### 消元过程 (Elimination)

消元过程从$A'$到$A^{(3)}$，得到了一个上三角矩阵：
$$
A^{(3)}=\begin{pmatrix}
2 & 4 & -2 & 2\\
0 & 1 & 1 & 4\\
0 & 0 & 1 & 2\\
\end{pmatrix}
$$
如果你学习线性代数只是为了考研，高斯消元法学到这里就可截止了，这个矩阵可以直接看出$x_3$，并在答卷上顺势看出$x_2,x_1$。你不一定在答卷上展示出下一个过程（回代），但你一定在心里走过一遍。

### 回代过程 (Backward Substitution)

回代过程从$A^{(3)}$到$A^{(5)}$，得到了一个单位矩阵：
$$
A^{(5)}=\begin{pmatrix}
1 & 0 & 0 & 1\\
0 & 1 & 0 & 2\\
0 & 0 & 1 & 2\\
\end{pmatrix}
$$
这个过程通过行变换，把对角线每一个元素的上方都变成了$0$，把对角线上每个元素都变成了1，从而让答案显而易见。

### 联系求逆矩阵 (Inverse)

你一定知道一个可逆矩阵怎么求逆矩阵，如果忘了就回顾一下：

对于一个矩阵$A$，把它和单位矩阵$I$平接成一个更大的矩阵$[A\quad I]$，通过行变换，将这个更大的矩阵的$A$部分变换为单位矩阵$I$的形式，此时右侧原$I$部分的形式就是$A^{-1}$。

在刚才的例子中，系数矩阵$A$是可逆的，方程的解可以直接表达成：
$$
x=A^{-1}b
$$
那么，上述消元的过程可以理解为代替求逆矩阵的过程，两个过程没有本质上的区别。它们可以得到相同的结果，也采用了相同的手法（矩阵拼接+行变换）！

求逆矩阵的过程和消元的过程，都采用了「矩阵拼接」手法，这是因为两个过程中的行变换都要同时作用在涉及到的两个矩阵上。

如果要解多个方程，每个方程组右侧常数$b$不同，而变量的系数相同，大可把多个列向量$b$一起拼接到系数矩阵$A$中，一系列行变换可以得到多个方程组的解。求匿矩阵的过程可以理解为同时求多个方程组解的过程。以上面的系数矩阵$A$为例，求$A^{-1}$就是在求以下三个方程组的解：
$$
\begin{aligned}
&2x_1+4x_2-2x_3=1\\
&4x_1+9x_2-3x_3=0\\
&-2x_1-3x_2+7x_3=0\\
\end{aligned},
\begin{aligned}
&2x_1+4x_2-2x_3=0\\
&4x_1+9x_2-3x_3=1\\
&-2x_1-3x_2+7x_3=0\\
\end{aligned},
\begin{aligned}
&2x_1+4x_2-2x_3=0\\
&4x_1+9x_2-3x_3=0\\
&-2x_1-3x_2+7x_3=1\\
\end{aligned}
$$
把上述三个方程组的列向量解拼接成一个矩阵，就是系数矩阵$A$的逆矩阵，如下描述。

把单位矩阵写成列向量的拼接：
$$
I=[u_1,u_2,u_3]
$$
把三个方程的解拼接成一个矩阵：
$$
X=[v_1,v_2,v_3]
$$
既然是解，那就必有$Av_j=u_j$，带入到乘法中：
$$
AX=[Av_1,Av_2,Av_3]=[u_1,u_2,u_3]=I
$$
只要求出解$v_1,v_2,v_3$，就可以得到逆矩阵！使用的是不同的表达方式，但是矩阵拼接、行变换都相同！

### 解方程的目的

对于$Ax=b$，解它的目的是回答这样一个问题：*矩阵$A$乘哪个向量$x$，会得到向量$b$?*

推广刚才联系逆矩阵的手法，对于一个矩阵$B$，我们同样可以解$AX=B$，回答这样一个问题：*矩阵$A$乘哪个矩阵$X$，会得到矩阵$B$？*对于求逆矩阵，就是在回答：*矩阵$A$乘哪个矩阵，会得到单位矩阵$I$？*

在一般的情况下，方程不一定有解$x$，或者不一定矩阵$X$。如果从向量空间和线性映射角度看，会有更深的理解，但这不是本文的重点。

以上举例子的是一个可逆的方形矩阵，方程只有一个解。以下看更一般的情况。

## 不止一个解的方程

你一定知道不止一个解的方程的存在，比如这个方程：
$$
Ax=0,A=\begin{pmatrix}
1 & 2 & 1\\
0 & 1 & 2\\
1 & 3 & 3\\
\end{pmatrix}
$$
消元之后，得到上三角矩阵：
$$
U=\begin{pmatrix}
1 & 2 & 1 \\
0 & 1 & 2 \\
0 & 0 & 0\\
\end{pmatrix}
$$
你可能已经发现了，$A$的第一行加第二行就是第三行！我故意选了一个简单的例子。

回代之后，不能得到单位矩阵：
$$
D=\begin{pmatrix}
1 & 0 & -3 \\
0 & 1 & 2 \\
0 & 0 & 0\\
\end{pmatrix}
$$
我们尝试把每个对角线元素上方的元素变成0，但是不可以，只能把其中的一些变成0。这里我们选择变第二列，而不是第三列，当然可以选第三列！

### 没有那么多个方程

你一定知道，一个方程组方程的个数，不是看上去这么简单。上面的方程组，直接写出来是这样：
$$
\begin{align}
&x_1+2x_2+x_3=0\\
&x_2+2x_3=0\\
&x_1+3x_2+3x_3=0\\
\end{align}
$$
然而$(1)+(2)=(3)$，这个方程组其实只有两个方程$(1),(2)$。我们说方程$(1),(2)$「线性独立」(linear independence)，而方程$(1),(2),(3)$「线性相关」(linear dependence)。

在矩阵中，这种现象表现为，消元后有一行（或好几行）是0，上三角矩阵的阶梯变「长」，一个阶梯包含多个数字。像矩阵$U$的第二行，阶梯上有$1,2$。之前的例子中，可逆矩阵进行消元后的阶梯上，都只有一个数字。阶梯上的元素，有在「阶梯脚」上的，如$D$第二行第二列的1，也有不在的，如$D$第二行第三列的2。

你也一定知道，方程个数少于未知量个数，这样的方程不能像原来那样得出单一的解。多一个方程就可以多一次消元的机会，方程个数少，就「消不完」。

对于上面的方程，「有效」的方程（独立的方程）只有前两个，两个方程最多只能消掉一个未知数。

在矩阵中，最终得到的矩阵$D$，表达成方程：
$$
\begin{align}
&x_1-3x_3=0\\
&x_2+2x_3=0\\
\end{align}
$$
这个方程组可以直接写出解。「解」是可以满足方程的形式，不一定是$x=\text{some number}$这样的形式。对于上面的方程组，解可以写成$x_1=3x_3,x_2=-2x_3$，向量形式就是$(3x_3,-2x_3,x_3)$。这个结果并不是「一个」解，而是「所有」解，是一个「集合」。当然，解还有很多种别的表达方式，这里选择的形式，用一个不确定的「自由」变量$x_3$可以描述三个变量的取值，是为更好的形式。当自由变量任意取值时，就可以创造出解的集合啦！

### 齐次方程的解

#### 算法

对于一个矩阵$A$，它对应的齐次方程就是$Ax=0$，方程右边是0。如果是更一般的方程$Ax=b$，解会复杂一些，我们待会再说。

上面的例子就是一个很好的求解过程，我们继续使用这个例子。上面的例子中，先进行了消元，然后使用尽量少的变量(一个$x_3$)描述解，而不使用其它形式。消元是固定化的，那么如何「使用尽量少的变量」呢？以下解决这个问题。

对于这个例子，注意到无论是上三角矩阵$U$还是回代之后的$D$，第二行的阶梯上，都多出来一个数字，正如刚才所说，这是「方程个数不够」造成的。阶梯上有「在阶梯脚上的」元素，如第二行第二列的1，也有不在的元素，如第二行第三列的2。我们选择不在阶梯脚上的元素，作为「自由变量」，使用单位矩阵填充。

在这里，我们先确定解的第三个位置上是$1$，也就是$x=(?,?,1)$，这就是「用单位矩阵填充」。
$$
D=\begin{pmatrix}
1 & 0 & -3 \\
0 & 1 & 2 \\
0 & 0 & 0\\
\end{pmatrix}\\
x=\begin{pmatrix}
?&?&1
\end{pmatrix}
$$
这当然还不是解，只是确定下了形式。有了这个假设，可以把这个$1$带入到其它方程中，即假设$x_3=1$，解$x_1,x_2$，最终得到的是$x=(3,-2,1)$。这是解吗？是的。是全部的解吗？不是。

全部的解应当是$x=c(3,-2,1)$，$c$是任意常数。你可以把这个结果带入原来的方程，验证$Ac(3,-2,1)^T=0$确实成立。你也可能注意到了，这和之前得到的$(3x_3,-2x_3,x_3)$具有相同形式。

你可能注意到，「用单位矩阵填充」，只是填充了一个$1$，而不是「单位矩阵」，本文在后面更详细地讲解这一点。在这里，$1$就是「一阶」单位矩阵，可理解为特殊情况。

#### 解释一下

为什么要加上这个常数？解释的方式有很多。这里我试图解释，而不做绝对严格的数学证明，以求符合直觉的理解。想要严格更深入的解释，请阅读本文余下内容。

方程数不够的时候，不能得到「唯一」解。方程是对变量的限制，而限制不够，变量的取值就是一个集合。限制太多，变量就无法取值，方程无解。限制刚好，变量就取在一个点上。

这样的限制，不会「只限制部分变量」或「只不限制部分变量」。我们可以看到，解$x=c(3,-2,1)$的三个分量都是乘上了变化的常数的，都是「自由不受限制」地变化的。而我们在解方程的时候，选择先确定第三个分量，只是操作上的方便/习惯。

这样没有乘上常数的向量$x=(3,-2,1)$叫做「基」或「解空间的基」。这样的一个「解集」或「解的集合」叫做「解空间」，也就是「解集」的意思啦。这方面的更多精彩内容，需要在「向量空间」下讨论。

#### 填充单位矩阵

用更大的矩阵举例，在这方面更加明显。我们换一个系数矩阵：
$$
A=\begin{pmatrix}
1 & 2 & 1 & 1\\
0 & 1 & 2 & 2\\
1 & 3 & 3 & 3\\
\end{pmatrix}
$$
这是在原来的矩阵$A$上加了一列。消元之后：
$$
D=\begin{pmatrix}
1 & 0 & -3 & -3\\
0 & 1 & 2 & 2 \\
0 & 0 & 0 & 0\\
\end{pmatrix}
$$
还是比原来的$D$多了一列。这样一来，第二行的「阶梯」就多了一个元素，也就是第四列的$2$。我们可以真的在这里「填充单位矩阵」啦。
$$
D=\begin{pmatrix}
1 & 0 & -3 & -3\\
0 & 1 & 2 & 2 \\
0 & 0 & 0 & 0\\
\end{pmatrix}\\
\beta_1=\begin{pmatrix}
?&?&1&0
\end{pmatrix}\\
\beta_2=\begin{pmatrix}
?&?&0&1
\end{pmatrix}
$$
这里采用$\beta_j$来表示填充产生的两个「基」，之前例子中只有一个「基」，这里有两个，没有本质上的区别。我特别把两个基摆在矩阵下方，就是想展示里面包含的单位矩阵！

剩下的操作和之前相同，对于$\beta_1$，把第3、4个分量的取值当作已知，可以得到前两个分量，$\beta_2$同理。最终的「解空间」由两个「基」的「线性组合」表示：
$$
x=c_1\beta_1+c_2\beta_2
$$

#### 总结一下算法

这里总结一下以上讲解的算法，使用于所有的「齐次方程」情况。

1. 消元，化成上三角形式$U$或回代后的形式$D$。
2. 给不在阶梯脚上的位置用单位矩阵填充，得到一组「基」。
3. 算出各个基其它分量上的值。
4. 所有基的线性组合就是解啦！

基的个数由「自由变量」的个数决定，「自由变量」的个数，由系数矩阵本省决定。

### 非齐次方程

非齐次就是更一般的情况，$Ax=b$，$b$不一定是0。只要对之前的算法作一丢丢改进，就可以得到「非齐次解」。

我们拿刚才的大矩阵举例，并且给出一个简单的$b$。
$$
A=\begin{pmatrix}
1 & 2 & 1 & 1\\
0 & 1 & 2 & 2\\
1 & 3 & 3 & 3\\
\end{pmatrix},b=\begin{pmatrix}
1\\
2\\
3\\
\end{pmatrix}
$$
和之前一样，把两个矩阵拼在一起，再进行行变换消元。
$$
A'=\begin{pmatrix}
1 & 2 & 1 & 1 & 1\\
0 & 1 & 2 & 2 & 2\\
1 & 3 & 3 & 3 & 3\\
\end{pmatrix}
,D=\begin{pmatrix}
1 & 0 & -3 & -3 & 1\\
0 & 1 & 2 & 2 & 2\\
0 & 0 & 0 & 0 & 0\\
\end{pmatrix}
$$
最后一个方程变成了$0=0$。

非齐次方程需要多一个「特解」，也需要「齐次解」。即便不是在解齐次方程，齐次解还是要算出来。对于不在阶梯脚上的「自由变量」，齐次情况下使用单位矩阵填充，非齐次情况下用0填充。最终的解是「齐次解」和「特解」的和。采用单位矩阵填充得到的基是齐次解，使用0填充得到的是特解。
$$
D=\begin{pmatrix}
1 & 0 & -3 & -3 & 1\\
0 & 1 & 2 & 2 & 2\\
0 & 0 & 0 & 0 & 0\\
\end{pmatrix}\\
\beta_1=\begin{pmatrix}
?&?&1&0
\end{pmatrix}\\
\beta_2=\begin{pmatrix}
?&?&0&1
\end{pmatrix}\\
\beta_p=\begin{pmatrix}
?&?&0&0
\end{pmatrix}
$$
注意到，特解$\beta_p$的自由变量的位置上是0，而齐次解$\beta_1,\beta_2$自由变量的位置上是单位矩阵。剩下的过程就是相同的啦，假设特解的3、4分量已知，带入求出前两个分量。这样求出的特解$\beta_p$一定符合原方程，$A\beta_p=b$。
$$
x=c_1\beta_1+c_2\beta_2+\beta_p
$$
你可以验证一下，看到这确实是方程的解。注意到，特解前没有系数，原因可以从验证的过程中看出。
$$
Ax=c_1A\beta_1+c_2A\beta_2+A\beta_p=A\beta_p=b
$$
如果特解前有系数，最后一个等号就不成立了。

更一般地说，非齐次情况的解，是齐次解和特解的和。齐次解和非齐次解差一个特解。

## 线性相关或独立

### 定义

为了描述「方程是否有效」，我们引入这个概念。如果两个方程相乘再相加（线性组合）可以产生第三个方程，那么这几个方程就不是「线性独立」的，就是「线性相关」的。

正如上面例子里面的那样。既然几个方程可以互相产生，那么一定有方程给出了「冗余的」（已经存在的）信息，可以大胆删掉了，它对求解过程没有贡献。

类似这样，我们也可以定义向量的线性相关/独立。对于一堆向量，如果其中一个向量可以由其它向量「表出」，那么它们就是「线性相关」的，否则就是「线性独立」的。用数学语言表述线性相关：
$$
\exists k\ne0,k_1v_1+...+k_nv_n=0
$$

### 秩

为了描述方程组中有几个方程是有效的，我们引入「秩」，秩就是「有效的」方程个数，通常用$r$表示。

要求解「秩」，只要采用高斯消元法就可以了。如上面大矩阵的例子，消元之后，最后一行都是0。
$$
D=\begin{pmatrix}
1 & 0 & -3 & -3 & 1\\
0 & 1 & 2 & 2 & 2\\
0 & 0 & 0 & 0 & 0\\
\end{pmatrix}
$$
最后一行对解的其它过程没有贡献，可以直接删除。有贡献的只有2行，那么「秩」就是$2$。

矩阵有多少行是「有效」的，通过消元就可以看出来，无效的行会变成0。

## 矩阵的各种形状和有解条件

有「高瘦」的矩阵，也有「矮胖」的矩阵，分别可以代表「方程个数大于未知数个数」和「方程个数小于未知数个数」。这样描述的「形状」不是真的形状，因为即便矩阵有多行/多列，这些行/列向量不一定是相互独立的。更多的行/列不一定给出了更多的信息。

所以，我们讲的「高瘦」应该指的是「列满秩」矩阵，也就是列向量都相互独立，「矮胖」就是「行满秩」矩阵，也就是行向量都相互独立，在这基础上，再加上行数大于/小于列数的形状条件。

### 高瘦列满秩

高瘦的矩阵代表「方程个数大于未知数个数」的情况。这样的情况可能令方程无解。我们可以看这样一个方程：
$$
Ax=b,A=\begin{pmatrix}
1 & 2\\
0 & 1\\
1 &4\\
\end{pmatrix},
b=\begin{pmatrix}
1\\
0\\
1\\
\end{pmatrix}
$$

我们对它进行拼接和消元：
$$
U=\begin{pmatrix}
1 & 2 & 1\\
0 & 1 & 0\\
0 & 2 & 1\\
\end{pmatrix}
$$
第二行和第三行自相矛盾啦！

要想让高瘦的矩阵方程有解，「有效」方程的个数不能大于未知数的个数，否则就会出现这样自相矛盾的情况。也就是说，$r\ge n$，$n$就是矩阵的列数，也是方程组未知量的个数。

把上述例子改成有解的：
$$
A=\begin{pmatrix}
1 & 2\\
0 & 1\\
1 &3\\
\end{pmatrix},
b=\begin{pmatrix}
1\\
1\\
2\\
\end{pmatrix}
$$
拼接消元后，变换成最简单形式：
$$
D=\begin{pmatrix}
1 & 0 & -1\\
0 & 1 & 1\\
0 & 0 & 0\\
\end{pmatrix}
$$
可以看出，系数矩阵可以变换成如下形式，顶上是一个单位矩阵，底下是一堆0。
$$
\begin{pmatrix}
I\\
0
\end{pmatrix}
$$

这样的情况*没有*自由变量，要么方程无解，要么只有一个解。

### 矮胖行满秩

和上面同理，矮胖的矩阵可以变换成如下形式。
$$
\begin{pmatrix}
I&F
\end{pmatrix}
$$
$F$是随机的矩阵，取决于原来矩阵的样子。举个例子：
$$
Ax=0,A=\begin{pmatrix}
1 & 2 & 1\\
0 & 1 & 1\\
\end{pmatrix}
$$
变换之后：
$$
D=\begin{pmatrix}
1 & 0 & -1\\
0 & 1 & 1\\
\end{pmatrix}
$$
这里的$F$就是最右侧的一列，表示「自由(free)变量」（叫做F的原因）。

自由变量当然不只出现在最边上，这里只是方便表达。也就是说，$F$的列可以和$I$的列交错出现在变换好的矩阵$D$中。

这样的情况*有*自由变量，方程有多个解。

### 综合情况

矩阵可以有「无效」的行，也可以有「多余」的列。

- 无效的行必须能够化成0，否则无解。
- 有解的高瘦矩阵，只有一个解。
- 多余的列表示自由变量，引发多个解。

我不会把方程组是否有解的各种情况列出来了，只求给大家一个直观的记忆方式。